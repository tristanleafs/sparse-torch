{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trist\\anaconda3\\envs\\env_torch\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\trist\\anaconda3\\envs\\env_torch\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Modules you need for this lab\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "\n",
    "# Other non-PyTorch Modules\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "def show_data(data_sample, size):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(size, size), cmap='gray')\n",
    "    plt.title(f\"Real Label = {labels[data_sample[1]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSparse(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # image, label = sample['image'], sample['label']\n",
    "\n",
    "        temp = (torch.rand(size=sample.shape) < 0.5).float()\n",
    "        return sample*temp\n",
    "\n",
    "        # return {'image': torch.multiply(image,temp), 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_SIZE = 24\n",
    "#Generates an object to store multiple transformations\n",
    "\n",
    "composed = transforms.Compose(\n",
    "    [transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    RandomSparse()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the two dataset objects and applying our transformations from above\n",
    "\n",
    "dataset_train = dsets.FashionMNIST(root= '.fashion/data', train=True, transform=composed,  download=True)\n",
    "  \n",
    "dataset_val = dsets.FashionMNIST(root= '.fashion/data', train=False, transform=composed,  download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAT9klEQVR4nO3de4xc5X3G8e9jG+z4Jtv4goOJCbcWVMgScbFaUnBKuDUUUAWCpIQiVJMKC4hSKJcoSSmkiEDgD1CEo1CgBadRwASJS0A0gZYEEgfMJUDEJSbg+Aa2sbEBY/vXP+a4DJtdv693zs6M930+0mjn8pvz/ubMPntmZt85RxGBmQ19wzrdgJm1h8NuVgiH3awQDrtZIRx2s0I47GaFcNg7SNKRkt4YhOUulnRUu+9bt97rp5t62xE57BmqX7J3Jb0jaZmkWySNbcO4IWnvwR5nsEn6maT3qvX3pqS7JE3vdF+lcdjznRARY4Ee4CDgks62s8OZW62/fYEJwHWdbSdNDUMmI0PmgbRLRCwDfkIj9ABImiXp55LWSHpa0pFNt50l6QVJ6yS9KumcVnuQtJek/5b0VrWlvF3ShF5lh0h6XtJqSf8uaVTT/T8vaVHV788lHdhqT7kiYhVwJ/BnVS8fefVSvWq6IrUcSSMlXS/pD9Xpekkjq9tekPT5ptoRklZK+nR1eVvP188kXSnpMWADsGc9j7zzHPbtJGkGcBzwcnV5N+Be4ApgEvBPwJ2SplR3WQF8HhgPnAVct/WXrpU2gH8DPg7sB+wOfLNXzReBY4C9aGxNv1b1exBwM3AOsAtwE3DP1qBsc1Dp4iogfZ6yGpcmA38LPJVTvw2XAbNo/NH9FHAo1WME5gOnN9UeA7wZEU9mPF8AZwBzgHHAay322T0iwqfECVgMvAOsAwJ4GJhQ3fbPwH/0qv8JcGY/y7obOL86fyTwxjbGDWDvjP5OAp7q1e+Xmy4fD7xSnf8u8K+97v9b4Iim+x5V8/r7GY2t5BpgCXA7MKWvxwjcAlzR1/pp7g14BTi+6bZjgMXV+b2r52p0dfl24Os5z1fV6+Wd/p0bjJO37PlOiohxNH4B/xSYXF0/Ezil1xbucGA6gKTjJD0uaVV12/FN9x0QSdMk/UDSEklrgf/sY5mvN51/jcargK39frVXv7s33T5YzouICRGxW0R8MSJWtri8j/PRre7/P8aIeBl4AThB0mjgb4A7qrptPl+V5nU3ZDjs2ykiHqGx9bmmuup1GluKCU2nMRFxVfXS+M6qdlpETADuo/EyvBXforFFPCAixgN/18cyd286/wngD039Xtmr39ERMT81qKRLq0/U+zwN8LFsAEY3Xd41835/oBHcrZofI3z4Uv5E4PnqDwBs4/lquu+Q/Cqowz4w1wOfk/QpGlvVEyQdI2m4pFHV/4dnADsDI4GVwCZJxwFHb+dYO1fL3HoaTuO95DvA29V70Av7uN+5kmZImkTj/e1/Vdd/D/iypMOqT5vHSPprSeNSjUTEtyJibH+n7XxcWy0CvlCtu2OBIzLvNx/4mqQp1ecAX6fxXGz1Axrr+h/5cKsO236+hjSHfQCql6C30Xgf+DqNrcelNEL9Oo3wDYuIdcB5wA+B1cAXgHu2c7jfAO82nc4C/gX4NPA2jQ+b7urjfncADwKv0nh/e0XV+0LgH4Abqp5eBv5+O3uq0/nACTTez3+RxmcaOa4AFgLPAM8CT1bXARARS4FfAH/Oh3/o2Nbz1dKj2AGo+lDCzIa4If/XzMwaHHazQjjsZoVw2M0KMaKdg0nyp4E1mDBhQrJm06ZNyZrNmzfX0A28++67tSxnzJgxyZr169fXMtZQFhF9zuNoa9itHrNnz07WrFq1KlmzZs2aZI2Unv+zaNGiZE2Onp6eZM1jjz1Wy1g5jwtgKP23qqWX8ZKOlfRbSS9LuriupsysfgMOezWT60Ya3wDbHzhd0v51NWZm9Wply34o8HJEvBoRG2lMTzyxnrbMrG6thH03PvrtoDeq6z5C0hxJCyUtbGEsM2vRoH9AFxHzgHngT+PNOqmVLfsSPvo1yhnVdWbWhVoJ+6+AfSR9UtLOwGls/ze6zKxNWvrWm6TjaXy3ezhwc0Rcmaj3y/ga5Px/PGfiTc6kmuHDh2d0lLZu3bpkzbhxya/U1+awww7LqnviiScGuZP6Dcqkmoi4j8aeV8ysy3luvFkhHHazQjjsZoVw2M0K4bCbFcJhNyuEw25WiLbuSnqoTqrJ2VEEwKRJk2oZb+XK9JGThg1L/x0fMSI9zSJnJw/jx49P1uT0nDOBJ6fnnH6Gsv4m1XjLblYIh92sEA67WSEcdrNCOOxmhXDYzQrhsJsVwmE3K0TRR4S57LLLkjVXXrnNne8A9U2WyTVq1KhkTc5eX5YvX56smTZtWlZPKTmTt9q5HnMnQv3oRz9K1sydOzdZs3HjxqzxBpO37GaFcNjNCuGwmxXCYTcrhMNuVgiH3awQDrtZIRx2s0IUPammp6cnWbN+/fpkzZgxY2roJl/OhJnVq1cnayZOnFhHOyxbtixZM3Xq1FrGqutx1TmBZ9ddd03W5KyjweYtu1khHHazQjjsZoVw2M0K4bCbFcJhNyuEw25WCIfdrBBFT6o55ZRTkjUbNmyobbxHHnkkWXPGGWcka37/+98na0aOHJnVUx0uueSSWpbz7W9/O1lT10SgXM8880yy5sADD2xDJ63zlt2sEC1t2SUtBtYBm4FNEXFwHU2ZWf3qeBk/OyLerGE5ZjaI/DLerBCthj2AByX9WtKcvgokzZG0UNLCFscysxa0+jL+8IhYImkq8JCkFyPi0eaCiJgHzAOQlN55uJkNipa27BGxpPq5AlgAHFpHU2ZWvwGHXdIYSeO2ngeOBp6rqzEzq1crL+OnAQskbV3OHRHxQC1d1WCnnXZK1tx9993JmpzDFuU64ogjaltWyujRo9s21po1a5I1hx9+eLLmwgsvTNbsu+++yZp77703WZOzdxnIe2xf+tKXkjW33XZb1niDacBhj4hXgU/V2IuZDSL/682sEA67WSEcdrNCOOxmhXDYzQrhsJsVwmE3K4TDblaIIbtbqg8++CBZ87GPfSxZk3Mct5yxIG9W344o57hpCxYsqGWs/fbbL1kzYkR9v9Zjx45N1nTD7Lgc3rKbFcJhNyuEw25WCIfdrBAOu1khHHazQjjsZoVw2M0KMWQn1ey9997Jms9+9rPJmnXr1iVrql1z1eLqq69O1lx00UXJmtmzZ9fRDp/5zGeSNZdffnmyJmfiydNPP52s6enpSdaMHz8+WTNu3LhkzVDjLbtZIRx2s0I47GaFcNjNCuGwmxXCYTcrhMNuVgiH3awQQ3ZSzYQJE5I1ixYtStbkTL7YvHlzRkfw3nvvJWvuv//+rGWlHHLIIcmanAk8s2bNqqMdDjrooGRNzjHTzj///GTNCSeckNVTXa6//vpkzQUXXDDofaR4y25WCIfdrBAOu1khHHazQjjsZoVw2M0K4bCbFcJhNyuEIqJ9g0ntG6yNctdhzqSat99+O1mzYcOGZM2ee+5Zy1gbN25M1uQcbmnixInJmmeffTZZc8ABByRrtmzZkqwZNmzobucios9dJyUfsaSbJa2Q9FzTdZMkPSTppepn+pk0s47K+fN2C3Bsr+suBh6OiH2Ah6vLZtbFkmGPiEeBVb2uPhG4tTp/K3BSvW2ZWd0G+kWYaRGxtDq/DJjWX6GkOcCcAY5jZjVp+VtvERHb+uAtIuYB82DofkBntiMY6EeSyyVNB6h+rqivJTMbDAMN+z3AmdX5M4Ef19OOmQ2WnH+9zQd+AfyJpDcknQ1cBXxO0kvAUdVlM+tiQ3ZSzcknn5ysWbBgQS1j5UxOAfjd736XrMk5vFFd3nrrrWRNzu/H5MmTaxlr+PDhyZpNmzbV0s9QNuBJNWY2NDjsZoVw2M0K4bCbFcJhNyuEw25WCIfdrBAOu1khhuzhn3IO27R06dJkzfTp05M1L774YlZPhx12WLImZ28277zzTrJG6nNexUfkTGLJOYxWjl122aWW5axa1fvb1n/sxhtvTNace+65WeOtX78+WXPvvfcma0499dSs8QaTt+xmhXDYzQrhsJsVwmE3K4TDblYIh92sEA67WSEcdrNCDNlJNbfddluy5tprr61lrJy9sABcffXVyZpRo0Yla1asSO/fs50TZnImukyaNClZs3bt2mTN+PHjs3qqS86hpNq5t6dWeMtuVgiH3awQDrtZIRx2s0I47GaFcNjNCuGwmxXCYTcrxJCdVPOVr3wlWTNlypRaxsrZmwnAzJkzaxlv6tSptSynrskwdY2VM4Fl8+bNyZqcCUW5hg1Lbw9Hjx5d23iDyVt2s0I47GaFcNjNCuGwmxXCYTcrhMNuVgiH3awQDrtZIYbspJq6Jla8//77yZqRI0dmLeuRRx5J1mzYsCFZkzOJY/Xq1cmanENE5SwnR85YOXvO+eCDD2roBpYtW5ZVN2JEOiKeVGNmXSUZdkk3S1oh6bmm674paYmkRdXp+MFt08xalbNlvwU4to/rr4uInup0X71tmVndkmGPiEeB9LcYzKyrtfKefa6kZ6qX+RP7K5I0R9JCSQtbGMvMWjTQsH8X2AvoAZYC/e6APSLmRcTBEXHwAMcysxoMKOwRsTwiNkfEFuB7wKH1tmVmdRtQ2CVNb7p4MvBcf7Vm1h2SMwYkzQeOBCZLegP4BnCkpB4ggMXAOYPX4sBcc801yZqciRU5E2auuuqqrJ5mzJiRrMmZoPHmm29mjVeHiRP7/TimdjmPq65DLa1cuTKrbtddd61lvIMPTr+LXbhwcD/WSoY9Ik7v4+rvD0IvZjaIPIPOrBAOu1khHHazQjjsZoVw2M0K4bCbFcJhNyvEkN1TzXnnnZesqWvCRO6eSnL2xLJ27dpkzfjx47PGS1mzZk2yJmdPNXVNvJk8eXKypq491SxfvryW5eQaNWpUW8fri7fsZoVw2M0K4bCbFcJhNyuEw25WCIfdrBAOu1khHHazQgzZSTVbtmypZTmbNm1K1tx///1Zy8o5lFBdE2Zy5EzyqevwTzneeuutZE1de6o56qijalkOwC9/+ctkzUUXXVTbeAPlLbtZIRx2s0I47GaFcNjNCuGwmxXCYTcrhMNuVgiH3awQDrtZIYbsDLobbrghWZNzrLecWW+51q9fn6ypazdQdS2nrpmIOYYNS297dt555zZ08qGcGXtPPfVUsqbO36OB8pbdrBAOu1khHHazQjjsZoVw2M0K4bCbFcJhNyuEw25WiM7/p7+D6jpu2DnnnJNVN2bMmFrGW7lyZbImZ3daOTZv3lzLcnLkPB8bN25M1jzwwAPJmvnz52f1JCmrbkeQ3LJL2l3STyU9L+k3ks6vrp8k6SFJL1U/6zm6n5kNipyX8ZuAr0bE/sAs4FxJ+wMXAw9HxD7Aw9VlM+tSybBHxNKIeLI6vw54AdgNOBG4tSq7FThpkHo0sxps13t2SXsABwFPANMiYml10zJgWj/3mQPMaaFHM6tB9qfxksYCdwIXRMTa5tui8dWgPr8eFBHzIuLgiDi4pU7NrCVZYZe0E42g3x4Rd1VXL5c0vbp9OrBicFo0szrkfBov4PvACxHxnaab7gHOrM6fCfy4/vbMrC4579n/AjgDeFbSouq6S4GrgB9KOht4DTh1UDo0s1okwx4R/wv0N7Pgr+ptpz6nnXZasub999+vZaybbrqpluXkmjJlSrLmrLPOqmWsSy65pJblnH322cmaqVOnJmvmzp2brHnllVeyemqno48+Olnz4IMPDmoPni5rVgiH3awQDrtZIRx2s0I47GaFcNjNCuGwmxXCYTcrhHIOb1PbYFL7BmujPfbYI6tu8eLFg9qHNeQcRqqdh7UCmDVrVrLm8ccfr2WsiOhzEpy37GaFcNjNCuGwmxXCYTcrhMNuVgiH3awQDrtZIRx2s0IM2Uk1M2fOTNa89tprtYyVs4cVgBUr0vvkzJkQ0k45k0+6cRJLyTypxqxwDrtZIRx2s0I47GaFcNjNCuGwmxXCYTcrhMNuVoh2T6pZSeO4cFtNBt5sWwP12RH7ds/t08m+Z0ZEn8cHa2vY/2hwaeGOeNz2HbFv99w+3dq3X8abFcJhNytEp8M+r8PjD9SO2Ld7bp+u7Luj79nNrH06vWU3szZx2M0K0bGwSzpW0m8lvSzp4k71sT0kLZb0rKRFkhZ2up/+SLpZ0gpJzzVdN0nSQ5Jeqn5O7GSPvfXT8zclLanW9yJJx3eyx94k7S7pp5Kel/QbSedX13fluu5I2CUNB24EjgP2B06XtH8nehmA2RHR043/R21yC3Bsr+suBh6OiH2Ah6vL3eQW/rhngOuq9d0TEfe1uaeUTcBXI2J/YBZwbvV73JXrulNb9kOBlyPi1YjYCPwAOLFDvQw5EfEosKrX1ScCt1bnbwVOamdPKf303NUiYmlEPFmdXwe8AOxGl67rToV9N+D1pstvVNd1uwAelPRrSXM63cx2mhYRS6vzy4BpnWxmO8yV9Ez1Mr8rXg73RdIewEHAE3TpuvYHdNvn8Ij4NI23H+dK+stONzQQ0fh/647wP9fvAnsBPcBS4NqOdtMPSWOBO4ELImJt823dtK47FfYlwO5Nl2dU13W1iFhS/VwBLKDxdmRHsVzSdIDqZ3pXtx0WEcsjYnNEbAG+Rxeub0k70Qj67RFxV3V1V67rToX9V8A+kj4paWfgNOCeDvWSRdIYSeO2ngeOBp7b9r26yj3AmdX5M4Efd7CXLFsDUzmZLlvfkgR8H3ghIr7TdFNXruuOzaCr/o1yPTAcuDkiruxII5kk7Uljaw4wArijW3uWNB84ksZXLZcD3wDuBn4IfILG14xPjYiu+UCsn56PpPESPoDFwDlN74U7TtLhwP8AzwJbd4x/KY337V23rj1d1qwQ/oDOrBAOu1khHHazQjjsZoVw2M0K4bCbFcJhNyvE/wG5ibNwfPT0mgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for n,data_sample in enumerate(dataset_val):\n",
    "\n",
    "    show_data(data_sample, IMAGE_SIZE)\n",
    "    plt.show()\n",
    "    if n==1:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Every PyTorch model must inherit from torch.nn.Module\n",
    "#nn.Module has very useful functions for models\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    # Constructor: (out_1: Output channels of first CNN Layer), (out_2: Output channels of second CNN Layer), (number_of_classes: Number of classes to detect)\n",
    "    def __init__(self, out_1=16, out_2=64, number_of_classes=10):\n",
    "        super().__init__()\n",
    "        #Create first Convolution Layer with input of 1 channel (grayscale) and output of out_1 channels\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        #Create a fully connected layer for the CNN. The input shape is the flattened convolution output. If output is (3, 28, 28), input is 28 * 28 * 3.\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(out_2 * 4 * 4, number_of_classes)\n",
    "\n",
    "        # Prediction (x is input)\n",
    "\t# The forward function is automatically called when we create an instance of the class and call it.\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "     \n",
    "        \n",
    "        #Flattening cnn2's output and passing it into a fully connected layer\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Loader for training data\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=100 )\n",
    "\n",
    "#Data Loader for validation data\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 1, 3),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(484, 10)\n",
    ")\n",
    "\n",
    "#Creating an Adam optimizer with a learning rate of 0.002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "\n",
    "#Use Cross Entropy Loss since this is a classification problem\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch no. 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:10<00:00, 59.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7099666666666666\n",
      "Validation accuracy: 0.7517\n",
      "\n",
      "Epoch no. 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:09<00:00, 60.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7780666666666667\n",
      "Validation accuracy: 0.7661\n",
      "\n",
      "Epoch no. 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:10<00:00, 59.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7838666666666667\n",
      "Validation accuracy: 0.775\n",
      "\n",
      "Epoch no. 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:09<00:00, 60.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7875833333333333\n",
      "Validation accuracy: 0.7765\n",
      "\n",
      "Epoch no. 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:09<00:00, 60.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7886666666666666\n",
      "Validation accuracy: 0.7792\n"
     ]
    }
   ],
   "source": [
    "# To show a progress bar while training\n",
    "from tqdm import tqdm\n",
    "\n",
    "training_acc_list=[]\n",
    "val_acc_list=[]\n",
    "N_test=len(dataset_val)\n",
    "N_train = len(dataset_train)\n",
    "n_epochs=5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    #Count how many predictions were correct\n",
    "    correct = 0\n",
    "\n",
    "    print()\n",
    "    print(f\"Epoch no. {epoch}\")\n",
    "    #Put model into training mode (uses Dropout if there are Dropout layers)\n",
    "    model.train()\n",
    "    #Loop over each sample in the dataloaders.\n",
    "    for x, y in tqdm(train_loader):\n",
    "        #Zero the optimizer gradients (PyTorch requires this.)\n",
    "        optimizer.zero_grad()\n",
    "        #Make a prediction\n",
    "        y_hat = model(x)\n",
    "        #Calculate the loss with the criterion\n",
    "        loss = criterion(y_hat, y)\n",
    "        #Initiate backpropagation/calculate derivatives of parameters with respect to the loss.\n",
    "        loss.backward()\n",
    "        #Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Update correct counter\n",
    "        #Grab the index of the AI's highest probability guess (Each output of model(x) is a tensor of probabilities) \n",
    "        correct += (torch.argmax(y_hat, 1) == y).sum().item()\n",
    "        \n",
    "    #Calculate accuracy\n",
    "    accuracy = correct / N_train\n",
    "    print(\"Training accuracy: \" + str(accuracy))\n",
    "    training_acc_list.append(accuracy)\n",
    "\n",
    "    correct=0\n",
    "    \n",
    "    #Put model into validation mode (turns off Dropout if there are Dropout layers)\n",
    "    model.eval()\n",
    "    for x_test, y_test in test_loader:\n",
    "        #Make a prediction\n",
    "        z = model(x_test)\n",
    "        #Grab the index of the AI's highest probability guess (Each output of model(x) is a tensor of probabilities) \n",
    "        y_hat = torch.argmax(z, 1)\n",
    "        #Update correct counter if the prediction was correct\n",
    "        correct += (y_hat == y_test).sum().item()\n",
    "    accuracy = correct / N_test\n",
    "    print(\"Validation accuracy: \" + str(accuracy))\n",
    "    val_acc_list.append(accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c74322094aab99573c56dbb21d7e1901a2c3b2c7428609116d3e4a163cd557a7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
